[tool.poetry]
name = "gptme-python"
version = "0.4.1"
description = "A fancy CLI to interact with LLMs in a Chat-style interface, with additional capabilities like executing commands on the local machine."
authors = ["Erik Bj√§reholt <erik@bjareho.lt>"]
readme = "README.md"
license= "MIT"
packages = [
    { include = "gptme" },
]

[tool.poetry.scripts]
gptme = "gptme.cli:main"

[tool.poetry.dependencies]
python = "^3.10"
openai = "^0.27"
click = "^8.0"
llama-cpp-python = {extras = ["server"], version = "^0.1.57", optional=true}
python-dotenv = "^1.0.0"
rich = "^13.5.2"
pick = "^2.2.0"
joblib = "^1.3.2"
toml = "^0.10.2"

[tool.poetry.group.dev.dependencies]
pytest = "^7.2"
pytest-cov = "*"
pytest-profiling = "^1.7.0"
mypy = "*"
ruff = "*"
black = "*"
types-toml = "^0.10.8.7"

[tool.poetry.extras]
server = ["llama-cpp-python"]

[tool.ruff]
ignore = ["E402", "E501"]

[tool.pytest.ini_options]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "serial",
]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
